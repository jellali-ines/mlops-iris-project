"""
Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ø¹ ØªØªØ¨Ø¹ MLflow
Training script with MLflow tracking
"""
import argparse
import os
import pickle
import time
from pathlib import Path

import mlflow
import mlflow.sklearn
import numpy as np
import pandas as pd
import yaml
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC


def load_config(config_path):
    """ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„ØªÙƒÙˆÙŠÙ†"""
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)


def prepare_data(csv_path='data/raw/iris.csv', test_size=0.2, random_state=42):
    """
    ØªØ­Ù…ÙŠÙ„ ÙˆØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    Load and prepare data
    """
    print("\nğŸ“Š ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    
    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† CSV
    df = pd.read_csv(csv_path)
    
    # ÙØµÙ„ Features Ùˆ Target
    X = df.drop(['target', 'species'], axis=1).values
    y = df['target'].values
    
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )
    
    # Scaling
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    print(f"âœ… Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {X_train.shape}")
    print(f"âœ… Ø­Ø¬Ù… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {X_test.shape}")
    
    return X_train_scaled, X_test_scaled, y_train, y_test, scaler


def train_model(config, X_train, y_train):
    """ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
    model_type = config['model']['type']
    params = config['model']['params']
    
    print(f"\nğŸ¤– ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬: {model_type}")
    
    if model_type == 'logistic_regression':
        model = LogisticRegression(**params)
    elif model_type == 'svm':
        model = SVC(**params)
    else:
        raise ValueError(f"Ù†ÙˆØ¹ Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ: {model_type}")
    
    start_time = time.time()
    model.fit(X_train, y_train)
    training_time = time.time() - start_time
    
    print(f"âœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙÙŠ {training_time:.2f} Ø«Ø§Ù†ÙŠØ©")
    
    return model, training_time


def evaluate_model(model, X_test, y_test):
    """ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
    print("\nğŸ“ˆ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
    
    y_pred = model.predict(X_test)
    
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='macro')
    conf_matrix = confusion_matrix(y_test, y_pred)
    class_report = classification_report(y_test, y_pred)
    
    print(f"âœ… Accuracy: {accuracy:.4f}")
    print(f"âœ… F1-Score: {f1:.4f}")
    
    return {
        'accuracy': accuracy,
        'f1_score': f1,
        'confusion_matrix': conf_matrix,
        'classification_report': class_report,
        'predictions': y_pred
    }


def save_model(model, scaler, output_dir, version):
    """Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    model_path = output_dir / f"model_{version}.pkl"
    scaler_path = output_dir / f"scaler_{version}.pkl"
    
    with open(model_path, 'wb') as f:
        pickle.dump(model, f)
    
    with open(scaler_path, 'wb') as f:
        pickle.dump(scaler, f)
    
    print(f"\nğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:")
    print(f"   - {model_path}")
    print(f"   - {scaler_path}")
    
    return str(model_path), str(scaler_path)


def main(args):
    print("=" * 70)
    print("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ - MLOps Iris Classification")
    print("=" * 70)
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙƒÙˆÙŠÙ†
    config = load_config(args.config)
    print(f"\nğŸ“‹ Ø§Ù„ØªÙƒÙˆÙŠÙ†: {args.config}")
    print(f"ğŸ“‹ Ø§Ø³Ù… Ø§Ù„ØªØ¬Ø±Ø¨Ø©: {config['experiment_name']}")
    print(f"ğŸ“‹ Ø§Ø³Ù… Ø§Ù„ØªØ´ØºÙŠÙ„: {config.get('run_name', 'training-run')}")
    
    # Ø¥Ø¹Ø¯Ø§Ø¯ MLflow
    mlflow_uri = os.getenv('MLFLOW_TRACKING_URI', 'http://localhost:5000')
    mlflow.set_tracking_uri(mlflow_uri)
    mlflow.set_experiment(config['experiment_name'])
    
    print(f"\nğŸ“Š MLflow URI: {mlflow_uri}")
    
    # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    X_train, X_test, y_train, y_test, scaler = prepare_data(
        test_size=config['data']['test_size'],
        random_state=config['data']['random_state']
    )
    
    # Ø¨Ø¯Ø¡ MLflow run
    with mlflow.start_run(run_name=config.get('run_name', 'training-run')):
        
        # ØªØ³Ø¬ÙŠÙ„ Parameters
        mlflow.log_params(config['model']['params'])
        mlflow.log_param('model_type', config['model']['type'])
        mlflow.log_param('test_size', config['data']['test_size'])
        mlflow.log_param('random_state', config['data']['random_state'])
        
        # Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        model, training_time = train_model(config, X_train, y_train)
        
        # Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
        metrics = evaluate_model(model, X_test, y_test)
        
        # ØªØ³Ø¬ÙŠÙ„ Metrics
        mlflow.log_metric('accuracy', metrics['accuracy'])
        mlflow.log_metric('f1_score', metrics['f1_score'])
        mlflow.log_metric('training_time', training_time)
        
        # ØªØ³Ø¬ÙŠÙ„ Artifacts
        mlflow.log_text(str(metrics['confusion_matrix']), 'confusion_matrix.txt')
        mlflow.log_text(metrics['classification_report'], 'classification_report.txt')
        
        # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        version = args.version if args.version else config.get('version', 'v1')
        model_path, scaler_path = save_model(model, scaler, 'models', version)
        
        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ MLflow (Ø¨Ø¯ÙˆÙ† log_model Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø®Ø·Ø£)
        # mlflow.sklearn.log_model(model, "model")  # ØªØ¹Ø·ÙŠÙ„ Ù…Ø¤Ù‚Øª
        mlflow.log_artifact(model_path)
        mlflow.log_artifact(scaler_path)
        
        # Tags
        mlflow.set_tags({
            'version': version,
            'framework': 'scikit-learn',
            'dataset': 'iris',
            'model_type': config['model']['type']
        })
        
        run_id = mlflow.active_run().info.run_id
        
        print("\n" + "=" * 70)
        print("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ù†Ø¬Ø§Ø­!")
        print("=" * 70)
        print(f"\nğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
        print(f"   - Accuracy: {metrics['accuracy']:.4f}")
        print(f"   - F1-Score: {metrics['f1_score']:.4f}")
        print(f"   - ÙˆÙ‚Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {training_time:.4f}s")
        print(f"\nğŸ’¾ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­ÙÙˆØ¸ ÙÙŠ: {model_path}")
        print(f"\nğŸ“ˆ MLflow:")
        print(f"   - Tracking URI: {mlflow_uri}")
        print(f"   - Run ID: {run_id}")
        print(f"\nğŸ’¡ Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ØŒ Ø§ÙØªØ­: {mlflow_uri}")
        print("=" * 70)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Iris')
    parser.add_argument('--config', type=str, default='configs/baseline.yaml',
                        help='Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„ØªÙƒÙˆÙŠÙ†')
    parser.add_argument('--version', type=str, help='Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬')
    
    args = parser.parse_args()
    main(args)