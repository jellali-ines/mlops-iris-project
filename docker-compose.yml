services:
  # MLflow Tracking Server (optional)
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.9.2
    container_name: mlflow-server
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlflow/mlruns
      - ./mlartifacts:/mlflow/mlartifacts
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri sqlite:///mlflow/mlruns/mlflow.db
      --default-artifact-root /mlflow/mlartifacts
    networks:
      - mlops-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Iris API v1 (Baseline - 93.33%)
  api-v1:
    build:
      context: .
      dockerfile: Dockerfile
    image: iris-api:v1
    container_name: iris-api-v1
    ports:
      - "8001:8000"
    volumes:
      - ./models:/app/models
    environment:
      - MODEL_VERSION=v1
      - MODEL_PATH=models/model_v1.pkl
    networks:
      - mlops-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Iris API v2 (Optimized - 100%)
  api-v2:
    build:
      context: .
      dockerfile: Dockerfile
    image: iris-api:v2
    container_name: iris-api-v2
    ports:
      - "8002:8000"
    volumes:
      - ./models:/app/models
    environment:
      - MODEL_VERSION=v2
      - MODEL_PATH=models/model_v2.pkl
    networks:
      - mlops-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

networks:
  mlops-network:
    driver: bridge